# KWF Energiemonitor API

Cloud-based API service for the KWF Energiemonitor project. This service receives telemetry data from NodeRED-equipped energy monitor devices and stores it in Google Cloud Firestore.

## Architecture

- **Framework**: Flask (Python)
- **Deployment**: Google Cloud Run
- **Database**: Google Cloud Firestore
- **Security**: Google Secret Manager for API keys
- **Export**: XLSX generation with openpyxl

## Project Structure

```
energiemonitor-api/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ telemetry.py    # Telemetry ingestion endpoint
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export.py       # Data export endpoint
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ telemetry.py    # Telemetry data model
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sensor.py       # Sensor metadata model
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ firebase_service.py # Firestore operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export_service.py   # XLSX generation
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.py             # Device key authentication
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py       # Data validation
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ firebase_config.py  # Configuration
‚îú‚îÄ‚îÄ tests/                       # Unit tests
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile                   # Container definition
‚îî‚îÄ‚îÄ cloudbuild.yaml             # GCP deployment config
```

## Firestore Datenstruktur

### Batch-Speicherung (Optimiert)

Das System verwendet eine **optimierte Batch-Speicherung**, die bis zu 2.000 Datenpunkte pro Dokument gruppiert. Dies reduziert die Schreibvorg√§nge um √ºber 99% und h√§lt die Kosten innerhalb des kostenlosen Kontingents.

```
/devices/{device_id}/
  ‚îú‚îÄ‚îÄ telemetry/
  ‚îÇ   ‚îú‚îÄ‚îÄ {year}/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {month}/
  ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ {day}/
  ‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ {sensor_id}_{metering_point}[_batch_nr]: {
  ‚îÇ   ‚îÇ               "sensor_id": "shelly-3em-pro",
  ‚îÇ   ‚îÇ               "device_id": "emon01",
  ‚îÇ   ‚îÇ               "metering_point": "E1",
  ‚îÇ   ‚îÇ               "date": "2025-10-12",
  ‚îÇ   ‚îÇ               "start_timestamp": 1728691200000,
  ‚îÇ   ‚îÇ               "end_timestamp": 1728777599999,
  ‚îÇ   ‚îÇ               "data_points": [
  ‚îÇ   ‚îÇ                 {
  ‚îÇ   ‚îÇ                   "timestamp": 1728691200000,
  ‚îÇ   ‚îÇ                   "values": {
  ‚îÇ   ‚îÇ                     "voltage": 231.5,
  ‚îÇ   ‚îÇ                     "act_power": 15.2,
  ‚îÇ   ‚îÇ                     "current": 1.5
  ‚îÇ   ‚îÇ                   }
  ‚îÇ   ‚îÇ                 },
  ‚îÇ   ‚îÇ                 // ... bis zu 2.000 Datenpunkte
  ‚îÇ   ‚îÇ               ],
  ‚îÇ   ‚îÇ               "count": 2000,
  ‚îÇ   ‚îÇ               "created_at": "2025-10-12T10:30:00Z"
  ‚îÇ   ‚îÇ             }
  ‚îú‚îÄ‚îÄ sensors/
  ‚îÇ   ‚îî‚îÄ‚îÄ {sensor_id}: {
  ‚îÇ       "sensor_id": "shelly-3em-pro",
  ‚îÇ       "sensor_type": "shelly-3em-pro",
  ‚îÇ       "metering_point": "E1",
  ‚îÇ       "first_seen": 1760084970005,
  ‚îÇ       "last_seen": 1760184970005,
  ‚îÇ       "data_count": 1234,
  ‚îÇ       "value_fields": ["voltage", "act_power", "pf"]
  ‚îÇ     }
```

### Vorteile der Batch-Speicherung

- **Kosteneffizienz**: >99% Reduktion der Schreibvorg√§nge
  - Vorher: ~259.200 Schreibvorg√§nge/Monat pro Ger√§t
  - Nachher: ~130 Schreibvorg√§nge/Monat pro Ger√§t
  - Kosten: $0.00 (innerhalb des kostenlosen Kontingents!)

- **Kalender-basierte Abfragen**: Organisiert nach Jahr/Monat/Tag
  - Ideal f√ºr XLSX-Exporte mit Datumsbereich
  - Abfragen von Mitternacht bis Mitternacht

- **Sensorisolierung**: Separate Dokumente pro Sensor + Messpunkt
  - Einfache Filterung nach Sensor-ID
  - Keine Vermischung verschiedener Sensoren

- **Dokumentgr√∂√üe**: ~265 KB bei 2.000 Datenpunkten
  - Nur 26% des 1-MB-Limits
  - 74% Sicherheitsmarge

### Pufferung und Speicherung

Das System puffert eingehende Daten im Speicher und schreibt sie in Batches:

1. **Automatisches Flushing**: Bei 2.000 Datenpunkten pro Sensor+Tag
2. **Manuelles Flushing**: Via `/buffer/flush` Endpoint
3. **Puffer-√úberwachung**: Via `/buffer/stats` Endpoint

**Beispiel-Dokumentpfad:**
```
/devices/emon01/telemetry/2025/10/12/shelly-3em-pro_E1
/devices/emon01/telemetry/2025/10/12/shelly-3em-pro_E2
/devices/emon01/telemetry/2025/10/12/shelly-3em-pro_E1_2  (bei >2000 Punkten)
```

## API Endpoints

### POST /telemetry

Receives telemetry data from NodeRED devices.

**Headers:**
- `KWF-Device-Key`: Device API key

**Request Body:**
```json
{
  "values": {
    "voltage": 231.27,
    "act_power": 14.555,
    "pf": 0.33,
    "aprt_power": 44.35
  },
  "sensor_id": "shelly-3em-pro",
  "timestamp": 1760084970005,
  "metering_point": "E1"
}
```

**Response:**
```json
{
  "message": "Data stored successfully",
  "device_id": "emon01",
  "sensor_id": "shelly-3em-pro",
  "timestamp": 1760084970005
}
```

### GET /export

Exportiert Telemetriedaten als XLSX-Datei zum Download.

**Service URL:**
```
https://telemetry-api-325255315766.europe-west6.run.app
```

**Headers:**
- `KWF-Device-Key`: Device API-Schl√ºssel (erforderlich)

**Query Parameter:**
- `start_date`: Startdatum (ISO-Format YYYY-MM-DD oder Timestamp in ms)
- `end_date`: Enddatum (ISO-Format YYYY-MM-DD oder Timestamp in ms)

**Beispiele:**

```bash
# Mit ISO-Datum
GET https://telemetry-api-325255315766.europe-west6.run.app/export?start_date=2025-10-01&end_date=2025-10-31

# Mit Timestamp (Millisekunden)
GET https://telemetry-api-325255315766.europe-west6.run.app/export?start_date=1727740800000&end_date=1730419199999

# Mit PowerShell herunterladen
$headers = @{
    "KWF-Device-Key" = "your-device-api-key"
}

Invoke-WebRequest `
    -Uri "https://telemetry-api-325255315766.europe-west6.run.app/export?start_date=2025-10-01&end_date=2025-10-31" `
    -Headers $headers `
    -OutFile "energiemonitor_export.xlsx"

# Mit curl herunterladen
curl -H "KWF-Device-Key: your-device-api-key" \
     "https://telemetry-api-325255315766.europe-west6.run.app/export?start_date=2025-10-01&end_date=2025-10-31" \
     -o energiemonitor_export.xlsx
```

**Response:**
- XLSX-Datei mit separaten Tabs f√ºr jeden Sensor
- Dateiname: `energiemonitor_{device_id}_{start_date}_{end_date}.xlsx`
- Spalten: Timestamp, Date/Time, Metering Point, Sensor ID, + alle Sensor-Werte

**XLSX-Struktur:**
```
Tab "shelly-3em-pro":
| Timestamp      | Date/Time           | Metering Point | Sensor ID       | voltage | act_power | current |
|----------------|---------------------|----------------|-----------------|---------|-----------|---------|
| 1728691200000  | 2025-10-12 00:00:00 | E1             | shelly-3em-pro  | 231.5   | 15.2      | 1.5     |
| 1728691210000  | 2025-10-12 00:00:10 | E1             | shelly-3em-pro  | 232.1   | 15.8      | 1.6     |
...

Tab "power-meter":
| Timestamp      | Date/Time           | Metering Point | Sensor ID    | power   | frequency |
|----------------|---------------------|----------------|--------------|---------|-----------|
| 1728691200000  | 2025-10-12 00:00:00 | K0             | power-meter  | 2300.0  | 50.0      |
...
```

**Hinweise:**
- ‚úÖ Daten werden aus der Batch-Speicherung extrahiert und entpackt
- ‚úÖ Automatische Sortierung nach Timestamp
- ‚úÖ Alle Sensoren in separaten Tabs
- ‚úÖ Spaltenbreiten automatisch angepasst
- ‚ö†Ô∏è Gro√üe Datenbereiche k√∂nnen l√§ngere Download-Zeiten verursachen

### GET /health

Health check endpoint for Cloud Run.

**Response:**
```json
{
  "status": "healthy"
}
```

### GET /buffer/stats

Zeigt Statistiken √ºber gepufferte Daten (keine Authentifizierung erforderlich).

**Response:**
```json
{
  "total_devices": 2,
  "devices": {
    "emon01": {
      "dates": 1,
      "sensors": {
        "shelly-3em-pro_E1": {
          "dates": {
            "2025-10-12": 1543
          },
          "total_points": 1543
        }
      },
      "total_points": 1543
    }
  }
}
```

### POST /buffer/flush

Manuelles Flushing des Puffers f√ºr ein Ger√§t.

**Headers:**
- `KWF-Device-Key`: Device API key

**Query Parameter (optional):**
- `date`: Spezifisches Datum zum Flushen (Format: YYYY-MM-DD)

**Beispiel:**
```
POST /buffer/flush
POST /buffer/flush?date=2025-10-12
```

**Response:**
```json
{
  "message": "Flushed 1 document(s)",
  "device_id": "emon01",
  "date": "2025-10-12"
}
```

## Verwendung / Usage

### Vollst√§ndiges Beispiel: Daten senden und exportieren

**Schritt 1: Telemetriedaten senden**

```powershell
# API-Schl√ºssel und URL definieren
$apiKey = "your-device-api-key"
$baseUrl = "https://telemetry-api-325255315766.europe-west6.run.app"

# Telemetriedaten senden
$headers = @{
    "KWF-Device-Key" = $apiKey
    "Content-Type" = "application/json"
}

$data = @{
    sensor_id = "shelly-3em-pro"
    metering_point = "E1"
    timestamp = [DateTimeOffset]::UtcNow.ToUnixTimeMilliseconds()
    values = @{
        voltage = 231.5
        act_power = 15.2
        current = 1.5
        power_factor = 0.95
    }
} | ConvertTo-Json

$response = Invoke-RestMethod -Uri "$baseUrl/telemetry" -Method POST -Headers $headers -Body $data
Write-Host "‚úì Daten gesendet: $($response.message)"
```

**Schritt 2: Pufferstatus pr√ºfen**

```powershell
# Pufferstatus abrufen (keine Authentifizierung erforderlich)
$bufferStats = Invoke-RestMethod -Uri "$baseUrl/buffer/stats"
Write-Host "Gepufferte Datenpunkte: $($bufferStats.devices.emon01.total_points)"
```

**Schritt 3: Daten als XLSX exportieren**

```powershell
# Daten f√ºr Oktober 2025 exportieren
$startDate = "2025-10-01"
$endDate = "2025-10-31"

$exportUrl = "$baseUrl/export?start_date=$startDate&end_date=$endDate"

# XLSX-Datei herunterladen
Invoke-WebRequest `
    -Uri $exportUrl `
    -Headers @{"KWF-Device-Key" = $apiKey} `
    -OutFile "energiemonitor_export_oktober_2025.xlsx"

Write-Host "‚úì Export erfolgreich: energiemonitor_export_oktober_2025.xlsx"
```

**Schritt 4: Optional - Puffer manuell flushen**

```powershell
# Puffer f√ºr spezifisches Datum flushen
$flushUrl = "$baseUrl/buffer/flush?date=2025-10-12"

$flushResponse = Invoke-RestMethod `
    -Uri $flushUrl `
    -Method POST `
    -Headers @{"KWF-Device-Key" = $apiKey}

Write-Host "‚úì Puffer geflusht: $($flushResponse.message)"
```

### Wichtige URLs

| Endpoint | URL |
|----------|-----|
| **Produktion** | `https://telemetry-api-325255315766.europe-west6.run.app` |
| Health Check | `https://telemetry-api-325255315766.europe-west6.run.app/health` |
| Telemetrie POST | `https://telemetry-api-325255315766.europe-west6.run.app/telemetry` |
| Export GET | `https://telemetry-api-325255315766.europe-west6.run.app/export` |
| Pufferstatus GET | `https://telemetry-api-325255315766.europe-west6.run.app/buffer/stats` |
| Puffer Flush POST | `https://telemetry-api-325255315766.europe-west6.run.app/buffer/flush` |

### Ger√§te-API-Schl√ºssel

Die folgenden Ger√§te sind konfiguriert:

| Device ID | Verwendung |
|-----------|------------|
| `emon01` | Produktionsger√§t 1 |
| `emon02` | Produktionsger√§t 2 |
| `emon03` | Produktionsger√§t 3 |
| `testmon00` | Testger√§t f√ºr Entwicklung |
| `testmon01` | Testger√§t f√ºr Batch-Tests |

**Hinweis:** Die tats√§chlichen API-Schl√ºssel sind in Google Secret Manager gespeichert.

## Setup & Deployment

### Prerequisites

1. Google Cloud Project with:
   - Cloud Run API enabled
   - Firestore database created
   - Secret Manager API enabled

2. Install Google Cloud SDK:
   ```bash
   # Install gcloud CLI
   # https://cloud.google.com/sdk/docs/install
   ```

3. Authenticate:
   ```bash
   gcloud auth login
   gcloud config set project YOUR_PROJECT_ID
   ```

### Store Device Keys in Secret Manager

```bash
# Create the secret with your device keys
gcloud secrets create energiemonitor-device-keys \
  --data-file=keys.json \
  --replication-policy="automatic"

# Grant Cloud Run access to the secret
gcloud secrets add-iam-policy-binding energiemonitor-device-keys \
  --member="serviceAccount:YOUR_PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"
```

**keys.json format:**
```json
{
  "emon01": "your-secure-device-key-1",
  "emon02": "your-secure-device-key-2",
  "emon03": "your-secure-device-key-3"
}
```

### Manual Deployment

```bash
# Build and deploy to Cloud Run
gcloud run deploy energiemonitor-api \
  --source . \
  --region europe-west6 \
  --platform managed \
  --allow-unauthenticated \
  --set-env-vars GCP_PROJECT=YOUR_PROJECT_ID
```

### Automated Deployment with Cloud Build

```bash
# Enable Cloud Build
gcloud services enable cloudbuild.googleapis.com

# Submit build
gcloud builds submit --config cloudbuild.yaml
```

### Wichtige Hinweise zur Batch-Speicherung

#### Puffer-Verhalten

Das System puffert Daten **im Speicher** und schreibt sie in Batches:

1. **Automatisches Flushing**: 
   - Erfolgt bei 2.000 Datenpunkten pro Sensor+Tag
   - Verhindert zu gro√üe Dokumente

2. **Datenverlust-Risiko**:
   - ‚ö†Ô∏è Puffer ist im Speicher - Daten gehen bei Service-Neustart verloren
   - ‚úÖ Durch automatisches Flushing bei 2.000 Punkten minimiert
   - üí° **Empfehlung**: Geplantes st√ºndliches Flushing einrichten

3. **Monitoring**:
   - Pufferstatus pr√ºfen: `GET /buffer/stats`
   - Manuelles Flushing: `POST /buffer/flush`

#### Batch-Gr√∂√üe konfigurieren

In `src/services/batch_buffer.py`:
```python
class BatchBuffer:
    MAX_POINTS_PER_BATCH = 2000  # Diesen Wert √§ndern
```

**Empfohlener Bereich**: 1.000 - 3.000 Datenpunkte
- Unter 1.000: Zu viele Schreibvorg√§nge
- √úber 3.000: Risiko zu gro√üer Dokumente

### Local Development

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export GCP_PROJECT=your-project-id
export GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account-key.json

# Run locally
python src/main.py
```

### Testing

```bash
# Run tests
pytest

# Run with coverage
pytest --cov=src tests/
```

## Security

### Device Authentication

- Each device has a unique API key stored in Google Secret Manager
- Keys are validated on every request via the `KWF-Device-Key` header
- Keys are cached in memory to reduce Secret Manager calls

### Best Practices

1. **Never commit keys**: Use Secret Manager for all sensitive data
2. **Rotate keys regularly**: Update device keys periodically
3. **Use HTTPS only**: Cloud Run enforces HTTPS
4. **Monitor access**: Use Cloud Logging to track API usage

## Monitoring & Logging

All logs are automatically sent to Google Cloud Logging:

```bash
# View logs
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=energiemonitor-api" --limit 50

# Monitor errors
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=energiemonitor-api AND severity>=ERROR" --limit 20
```

## Cost Optimization

### Firestore Batch-Speicherung

Das System verwendet eine hochoptimierte Batch-Speicherung:

- **Vorher** (einzelne Dokumente):
  - ~8.640 Schreibvorg√§nge pro Tag und Ger√§t
  - ~259.200 Schreibvorg√§nge pro Monat
  - Kosten: $0.47/Monat pro Ger√§t (nach Free Tier)

- **Nachher** (Batch-Dokumente mit 2.000 Punkten):
  - ~5 Schreibvorg√§nge pro Tag und Ger√§t
  - ~130 Schreibvorg√§nge pro Monat
  - **Kosten: $0.00/Monat (innerhalb Free Tier!)**
  - **Einsparung: >99% Reduktion**

- **Abfrage-Optimierung**:
  - Organisiert nach Jahr/Monat/Tag
  - Nur ~5 Dokument-Lesevorg√§nge pro Tag (statt 8.640)
  - Effiziente Datumsbereichsabfragen

### Cloud Run

- **Pay per request**: Auto-Scaling auf Null bei Inaktivit√§t
- **Konfiguration**: `--min-instances=0` f√ºr maximale Kosteneinsparung
- **Cold Starts**: Akzeptabel f√ºr Telemetrie-Anwendung

### Secret Manager

- **Caching**: API-Keys werden im Speicher gecacht
- **Minimale Zugriffe**: Nur beim ersten Request nach Neustart

## Future Enhancements

### Empfohlene n√§chste Schritte

- [ ] **Persistenter Puffer** (Hohe Priorit√§t)
  - Pufferzustand in Firestore oder Cloud Storage speichern
  - Wiederherstellung nach Service-Neustart
  - Verhindert Datenverlust

- [ ] **Geplantes Flushing** (Hohe Priorit√§t)
  - Cloud Scheduler Job f√ºr periodisches Flushing (z.B. st√ºndlich)
  - Automatisches Flushing um Mitternacht (UTC)
  - Erh√∂ht Datensicherheit

- [ ] **Puffer-Monitoring Dashboard**
  - Visualisierung der gepufferten Daten
  - Alerts bei Anomalien
  - √úberwachung pro Ger√§t/Sensor

- [ ] Datenaggregation (st√ºndliche/t√§gliche Zusammenfassungen)
- [ ] Ger√§testatus-Monitoring implementieren
- [ ] Webhook-Benachrichtigungen f√ºr Alarme
- [ ] Admin-Dashboard erstellen
- [ ] Datenaufbewahrungsrichtlinien
- [ ] Backup-Strategie implementieren

## Support

For questions or issues:
- Email: energiemonitor@kleinwohnformen.ch
- GitHub: https://github.com/Verein-Kleinwohnformen

## License

Open Source - maintained by [Verein Kleinwohnformen](https://kleinwohnformen.ch)
